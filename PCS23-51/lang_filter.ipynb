import nltk 
def removeNonEnglishWordsFunct(x):
    words = set(nltk.corpus.words.words())
    filteredSentence = " ".join(w for w in nltk.wordpunct_tokenize(x) \
                                if w.lower() in words or not w.isalpha())
    return filteredSentence


string = "NLTK testing man Apple Confiz Burj Al Arab Copacabana Palace Ｗは比較的新しくてきれいなのですが Ｓｈｅｒａｔｏｎ hotelは時々 ＮＹらしい小さくて清潔感のない部屋"

res = removeNonEnglishWordsFunct(string)
# # nltk.download('words')
# words = set(nltk.corpus.words.words())

# sent = "Io andiamo to the beach with my amico."
# sent = " ".join(w for w in nltk.wordpunct_tokenize(sent) if w.lower() in words or not w.isalpha())
# print(sent)
# from textblob import TextBlob
# import pandas as pd
# reindexed_data = pd.read_csv("new_ptsd.csv")
# test = reindexed_data.head()
# indices = []
# index = 0
# for adv in test:
#     x = TextBlob(adv)
#     if (x.detect_language() == "en"):
#         indices.append(index)
#     index+=1

# test_en = test.loc[indices]